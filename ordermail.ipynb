{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_P9Vs_7pLmh"
   },
   "source": [
    "Created on March 21st 2020 by Patrick Rotzetter\n",
    "Last update on Feb 28th 2021\n",
    "\n",
    "protzetter@bluewin.ch\n",
    "https://www.linkedin.com/in/rotzetter/\n",
    "\n",
    "**Small experiment for order mail processing**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qPF1dXXBpLm4"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.matcher import Matcher,PhraseMatcher\n",
    "from spacy.symbols import nsubj, VERB, dobj, NOUN, root, xcomp\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from pathlib import Path\n",
    "import random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFSOtLgPlvXh",
    "outputId": "3a5e9c8c-e10a-4a64-e096-cdd02578ce39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.0.1) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation:\n",
      "/opt/anaconda3/envs/spacy30/lib/python3.8/site-packages/spacy\u001b[0m\n",
      "\n",
      "NAME              SPACY            VERSION                            \n",
      "en_core_web_lg    >=3.0.0,<3.1.0   \u001b[38;5;2m3.0.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "en_core_web_sm    >=3.0.0,<3.1.0   \u001b[38;5;2m3.0.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "en_core_web_trf   >=3.0.0,<3.1.0   \u001b[38;5;2m3.0.0\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G0kIIbSlRigk",
    "outputId": "19fce0d5-9c4b-4854-cd35-0938ef946e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n",
      "Name: spacy\n",
      "Version: 3.0.1\n",
      "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
      "Home-page: https://spacy.io\n",
      "Author: Explosion\n",
      "Author-email: contact@explosion.ai\n",
      "License: MIT\n",
      "Location: /opt/anaconda3/envs/spacy30/lib/python3.8/site-packages\n",
      "Requires: murmurhash, preshed, cymem, tqdm, catalogue, wasabi, srsly, jinja2, typer, pydantic, requests, blis, spacy-legacy, pathy, packaging, setuptools, thinc, numpy\n",
      "Required-by: texthero, en-core-web-trf, en-core-web-sm, en-core-web-lg\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "!pip show spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GixaCyvwaHTZ"
   },
   "outputs": [],
   "source": [
    "# load spacy model latets modle based on pre-trained transformer model Roberta\n",
    "\n",
    "from spacy.lang.en import English\n",
    "import en_core_web_trf\n",
    "nlp = en_core_web_trf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mlh4tq5ppLnD",
    "outputId": "1be2524a-1438-4453-de6f-801e27860255"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello,  I would like to order a notebook with 16GB and 256 GB disk, I would like to spend less than 1000 Francs, what would be the options  Thanks a lot  Patrick\n"
     ]
    }
   ],
   "source": [
    "#read order dialog file\n",
    "\n",
    "text = open('ordermail.txt').read().replace('\\n', ' ')\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MM2JLVdDpLnP"
   },
   "outputs": [],
   "source": [
    "#process the mail trough standard spacy pipeline\n",
    "doc=nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfqjYwm-pLnY",
    "outputId": "0c0d80a5-c28a-4d64-9ee0-813346ff8b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16GB QUANTITY\n",
      "256 GB QUANTITY\n",
      "1000 Francs QUANTITY\n",
      "Patrick PERSON\n"
     ]
    }
   ],
   "source": [
    "# print text entities detected\n",
    "for ent in doc.ents :\n",
    "    print(ent.text, ent.label_,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello,  I would like to order a notebook with <mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">16GB<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span></mark> and <mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">256 GB<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span></mark> disk, I would like to spend less than <mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">1000 Francs<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span></mark>, what would be the options  Thanks a lot  <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Patrick<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let us visualize the result directly in the text\n",
    "displacy.render(doc, style='ent', minify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model does not seem to detect notebook and disk as entities, but identifies the sender as a person and identifies the RAM and disk size as quantities. This is a good start, but still far away from a practical solution. So, let us add some domain specific entities that will help us later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ktTxXUv6pLnm"
   },
   "outputs": [],
   "source": [
    "# add domain specific entities and add to the pipeline\n",
    "patterns = [{\"label\": \"CURRENCY\", \"pattern\":  [{\"lower\": \"francs\"}]},\n",
    "            {\"label\": \"PART\", \"pattern\":  [{\"lower\": \"disk\"}]}]\n",
    "\n",
    "\n",
    "config = {\n",
    "   \"phrase_matcher_attr\": None,\n",
    "   \"validate\": True,\n",
    "   \"overwrite_ents\": True,\n",
    "   \"ent_id_sep\": \"||\",\n",
    "}\n",
    "ruler=nlp.add_pipe('entity_ruler',config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGXjca-QpLnw",
    "outputId": "ce015e62-7de1-49e2-ee0f-5dc729a5162e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16GB QUANTITY\n",
      "256 GB QUANTITY\n",
      "disk PART\n",
      "Francs CURRENCY\n",
      "Patrick PERSON\n"
     ]
    }
   ],
   "source": [
    "#process the mail again with added entities\n",
    "doc=nlp(text)\n",
    "for ents in doc.ents:\n",
    "    # Print the entity text and its label\n",
    "    print(ents.text, ents.label_,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "PneiF9bEeN6Y",
    "outputId": "6742ffa1-a9e0-48fc-cc7d-970042baad12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello,  I would like to order a notebook with <mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">16GB<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span></mark> and <mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">256 GB<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span></mark> <mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">disk<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PART</span></mark>, I would like to spend less than 1000 <mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Francs<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CURRENCY</span></mark>, what would be the options  Thanks a lot  <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">Patrick<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let us visualize the result directly in the text\n",
    "displacy.render(doc, style='ent', minify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KIMIRSvfpLn4",
    "outputId": "7d2b1736-124b-435b-fd4b-bcd2589bf0d6"
   },
   "outputs": [],
   "source": [
    "# Let us try to identify specific phrases or sequence of words, for example to detect the memory size\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "terms = [\"16 GB\",\"256 GB\"]\n",
    "# Only run nlp.make_doc to speed things up\n",
    "patterns = [nlp.make_doc(t) for t in terms]\n",
    "matcher.add(\"MEMORY\", None, *patterns)\n",
    "\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6f_65tpdU5B",
    "outputId": "aaa2c503-1cbc-4010-8b5e-220aa3241c7c"
   },
   "outputs": [],
   "source": [
    "# Part of speech tagging\n",
    "# This is where the trained pipeline and its statistical models come in, \n",
    "# which enable spaCy to make predictions of which tag or label most likely applies in this context\n",
    "for token in doc:\n",
    "  print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "7GVukhKHpLoC",
    "outputId": "3c774548-0595-4c42-b9a1-786b90a97226"
   },
   "outputs": [],
   "source": [
    "# visualize the dependency graph\n",
    "displacy.render(doc, style=\"dep\", minify=True, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy provides all the required tagging to find the action verbs, we want to know if the customer wants to order something or is just interested by some information for example. Let us iterate through all tokens in the text and search for an open clausal complement ( refer to for all possible dependency tags https://spacy.io/api/annotation#pos-tagging )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5YKyxgGupLop",
    "outputId": "7b852884-67d7-4224-f230-d318cf4aa5b0"
   },
   "outputs": [],
   "source": [
    "# Identify action verbs\n",
    "verbs = set()\n",
    "for possible_verbs in doc:\n",
    "    if possible_verbs.dep == xcomp and possible_verbs.head.pos == VERB :\n",
    "        verbs.add(possible_verbs)\n",
    "print(verbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find possible items in the text using the dependency tag ‘dobj’ for direct objects of a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zgv8UTPGiZZy",
    "outputId": "7f804d85-4e50-482f-d710-72e17d9a114f"
   },
   "outputs": [],
   "source": [
    "# Let us find possible items in the text using the dependency tag ‘dobj’ for direct objects of a verb.\n",
    "items = set()\n",
    "for possible_subject in doc:\n",
    "    if possible_subject.dep == dobj and possible_subject.head.pos == VERB:\n",
    "        items.add(possible_subject)\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFTh6iJapLog",
    "outputId": "de0a83f7-ca26-4df1-d479-0ff1b717ed01"
   },
   "outputs": [],
   "source": [
    "# We will compare similarities between identified objects and the word ‘laptop’. \n",
    "# The word ‘notebook’ is much closer to ‘laptop’ than Francs.\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()\n",
    "orderobject=nlp(\"laptop\")\n",
    "for  sub in items:\n",
    "  print(sub.text,nlp(sub.text).similarity(orderobject))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHNG7j5ApLou",
    "outputId": "22c29c19-bf3b-4e3a-a3a8-264462f052d4"
   },
   "outputs": [],
   "source": [
    "# We will compare similarities between identified verbs and the verb ‘order’. \n",
    "# Then based on this we will identiofy the direct object of the verb\n",
    "orderword=nlp(\"order\") \n",
    "for  verb in verbs:\n",
    "  if (nlp(verb.text).similarity(orderword)) >=0.8:\n",
    "    for v in verb.children:\n",
    "      if v.dep==dobj:\n",
    "        print(v.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1nDnp2adwjE",
    "outputId": "37afdd92-1e7f-4705-b83e-5309fd2d7a00"
   },
   "outputs": [],
   "source": [
    "# we can also identify specific slots using numeric modifiers for example to understand the desired quantities\n",
    "# with corresponding modified objects\n",
    "for token in doc:  \n",
    "    if token.dep_ == 'nummod':    \n",
    "      print(f\"Numerical modifier: {token.text} --> object: {token.head}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXtNM5rdvUOH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ordermail.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
